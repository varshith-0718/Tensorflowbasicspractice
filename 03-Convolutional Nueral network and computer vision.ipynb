{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMvKFHklL1zZdwGS3pz+rxJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Computer vision** is the pratice of writing algorithms which can discover patterns in visual data. Such as the camera of a self-driving car recognizing the in front etc.,"],"metadata":{"id":"kQ-gont49Xe5"}},{"cell_type":"markdown","source":["#Get the data\n","\n","The images we're working with are from the Food101 dataset (101 different classes of food): https://www.kaggle.com/dansbecker/food-101\n","\n","But we are using only the modified part which only contains 2 classes that is (pizza and steak) using the image data modification in the link:\n","https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb"],"metadata":{"id":"P1k0jgLyM8bB"}},{"cell_type":"code","source":["import zipfile\n","\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n","\n","#unzip the downloaded file\n","zip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\n","zip_ref.extractall()\n","zip_ref.close()"],"metadata":{"id":"LE4OVUo1941V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inspect the data\n","\n","Visualizing many samples of data\n"],"metadata":{"id":"d4W-vbT9d8yD"}},{"cell_type":"code","source":["!ls pizza_steak\n"],"metadata":{"id":"OKIwy60FCgKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls pizza_steak/train/"],"metadata":{"id":"qIDSileNeQfN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls pizza_steak/train/steak"],"metadata":{"id":"_mModdEbeWxs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","#walk through pizza_steak directory and list number of files\n","\n","for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n"],"metadata":{"id":"S7Zi4XQ1eaFj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So, there are 750 images of steak in trainset of steak, 250 images of steak images in testset of steak similarly the train and test sets of pizza's have 750 and 250 images respectfully."],"metadata":{"id":"RoQmo2-QfQJg"}},{"cell_type":"code","source":["!ls -la pizza_steak"],"metadata":{"id":"vqNfk4fyfG7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Another way to find out how many images are in a file\n","num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n","\n","num_steak_images_train"],"metadata":{"id":"hYm3kM2NfMHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To visualize our images, first let's class names programmatically."],"metadata":{"id":"5TTFaRBogDtF"}},{"cell_type":"code","source":["import pathlib\n","import numpy as np\n","data_dir = pathlib.Path(\"pizza_steak/train\")\n","\n","class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) #created a list of class names from the subdirectories"],"metadata":{"id":"QkdEI8oYgDQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names\n","# if we have a .DS_store or any other extra files or folders in your current folder you are accessing use if its your first file.\n","#class_names = class_names[1:]"],"metadata":{"id":"1QbZUguJgu8a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Let's visualize our images\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import random\n","\n","def view_random_image(target_dir, target_class):\n","  #setting up the target directory\n","  target_folder = target_dir  +target_class\n","\n","  #get a random image path\n","  random_image = random.sample(os.listdir(target_folder),1) #It randomly samples one of the image in the target folder.\n","  print(random_image)\n","  print(random_image[0])\n","\n","  #Read in the image and plot it using the matplotlib\n","  img = mpimg.imread(target_folder + \"/\" + random_image[0]) #[0] because it return back as list ['x_ooo.img'] so we index so it return back as the string 'x_ooo.img'\n","  plt.imshow(img)\n","  plt.title(target_class)\n","  plt.axis(\"off\")\n","\n","  print(f\"Image shape: {img.shape}\") #shape is (224,224)\n","  return img"],"metadata":{"id":"wxzghj60hPbm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#view the random image from the training dataset.\n","img = view_random_image(target_dir = \"pizza_steak/train/\",\n","                        target_class = \"steak\")"],"metadata":{"id":"xYlOymq4jRR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.constant(img)"],"metadata":{"id":"8x8_v3p7kTpp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#view the image shape\n","img.shape #returns width ,height , colour channels\n"],"metadata":{"id":"79YCH2X9k2q2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get all the pixel values between 0 and 1\n","img/255."],"metadata":{"id":"NtX9E_lLv-22"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#An end to end example\n","\n","Let's build a convolutional neural network to find patterns in our images:\n","\n","* Load our images\n","* Preprocess our images\n","* Build a CNN to find patterns in our images.\n","* Compile our CNN\n","* Fit the CNN to our training data\n","\n"],"metadata":{"id":"ZPhw2x2DxluT"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","#Set the seed\n","tf.random.set_seed(42)\n","\n","#process data(get all of the pixel values between 0 & 1 also called scaling/normalization)\n","train_datagen = ImageDataGenerator(rescale = 1./255)\n","valid_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#setup the paths to our data directories\n","train_dir = \"/content/pizza_steak/train/\"\n","test_dir = \"/content/pizza_steak/test/\"\n","\n","#Import data from  directories and turn it into batches\n","train_data = train_datagen.flow_from_directory(directory = train_dir,\n","                                               batch_size = 32,\n","                                               target_size = (224,224),\n","                                               class_mode = \"binary\",\n","                                               seed = 42\n","                                               )\n","valid_data = train_datagen.flow_from_directory(directory = test_dir,\n","                                               batch_size = 32,\n","                                               target_size = (224,224),\n","                                               class_mode = \"binary\",\n","                                               seed = 42\n","                                               )\n","\n","#Build a CNN model (same as the tiny VGG on the CNN)\n","\n","model_1 = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(filters = 10,\n","                           kernel_size = 3,\n","                           activation ='relu',\n","                           input_shape = (224,224,3)),\n","    tf.keras.layers.Conv2D(10,3,activation = 'relu'),\n","    #tf.keras.layers.Activations(tf.nn.relu), we can use the activation this way instead of putting it into a Conv2D layer as in the above line.\n","    tf.keras.layers.MaxPool2D(pool_size=2,\n","                              padding = \"valid\"),\n","    tf.keras.layers.Conv2D(10,3,activation = 'relu'),\n","    tf.keras.layers.Conv2D(10,3,activation = 'relu'),\n","    tf.keras.layers.MaxPool2D(2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(1,activation = 'sigmoid')\n","])\n","\n","#compile our CNN\n","\n","model_1.compile(loss = 'binary_crossentropy',\n","                optimizer = tf.keras.optimizers.Adam(),\n","                metrics = ['accuracy'])\n"],"metadata":{"id":"Uw1na0SLxa3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train_data)"],"metadata":{"id":"lEZ9JDNL9i2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1500/32\n","\n","# So, we have 47 batches of 32 images and labels\n","# we split it into batches because if try to fit all the 1500 images the computer might run out of memory"],"metadata":{"id":"HuPm6uEp9nGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data\n"],"metadata":{"id":"Usqh5HgS-GjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.class_indices"],"metadata":{"id":"FavjAqz5X-DO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a batch of data\n","images, labels = next(train_data)\n","\n","# Display shapes of the images and labels\n","print(f\"Images shape: {images.shape}\")\n","print(f\"Labels shape: {labels.shape}\")\n","\n","# Example: Display the first image and its label\n","import matplotlib.pyplot as plt\n","\n","plt.imshow(images[0])  # Display the first image\n","plt.title(f\"Label: {labels[0]}\")  # Show the label\n","plt.axis(\"off\")\n","plt.show()\n"],"metadata":{"id":"FNI-3jH5ZKIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Get a single batch of data\n","images, labels = next(train_data)\n","\n","# Flatten each image (convert from 3D to 1D)\n","flattened_images = images.reshape(images.shape[0], -1)\n","\n","# Create a DataFrame\n","df = pd.DataFrame(flattened_images)\n","df['Label'] = labels  # Add labels as a column\n","\n","print(df.head())  # View the DataFrame\n"],"metadata":{"id":"3kWlmeLSaFGH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Using the same model as before(classification model)"],"metadata":{"id":"XmOZnFWGUuYE"}},{"cell_type":"code","source":["#set random seed\n","tf.random.set_seed(42)\n","\n","# Create a model to replicate the Tensorflow playground model\n","\n","model_2 = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape = (224,224,3)),\n","    tf.keras.layers.Dense(4,activation = 'relu'),\n","    tf.keras.layers.Dense(4,activation = 'relu'),\n","    tf.keras.layers.Dense(1,activation = 'sigmoid')\n","])\n","\n","# Compile the model\n","\n","model_2.compile(loss = 'binary_crossentropy',\n","                optimizer = tf.keras.optimizers.Adam(),\n","                metrics = ['accuracy'])\n","\n","# Recreate train_data and valid_data here as they were defined earlier in the notebook\n","# to avoid issues with the data loader\n","#process data(get all of the pixel values between 0 & 1 also called scaling/normalization)\n","train_datagen = ImageDataGenerator(rescale = 1./255)\n","valid_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","#setup the paths to our data directories\n","train_dir = \"/content/pizza_steak/train/\"\n","test_dir = \"/content/pizza_steak/test/\"\n","\n","#Import data from  directories and turn it into batches\n","train_data = train_datagen.flow_from_directory(directory = train_dir,\n","                                               batch_size = 32,\n","                                               target_size = (224,224),\n","                                               class_mode = \"binary\",\n","                                               seed = 42\n","                                               )\n","valid_data = train_datagen.flow_from_directory(directory = test_dir,\n","                                               batch_size = 32,\n","                                               target_size = (224,224),\n","                                               class_mode = \"binary\",\n","                                               seed = 42\n","                                               )\n","\n","# fit the model\n","history_2 = model_2.fit(train_data,\n","                        epochs =5,\n","                        steps_per_epoch = len(train_data)-1,\n","                        validation_data = valid_data,\n","                        validation_steps = len(valid_data)-1\n","                        )"],"metadata":{"id":"TrfcR8h8Unz-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Despite having more parameters model_2 underperforms over CNN(model_1)"],"metadata":{"id":"hQlXaUGgbpCX"}},{"cell_type":"code","source":["model_2.summary()"],"metadata":{"id":"vM_DQB4RbAGE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The trainable parameters are like patterns a model can learn from data. Intutively(more is better) normal classification just classifies based on the series of parametrs in its dense layer but convolutional layer seeks to sort out and learn most important patterns in an image. So even though it has less learnable parameters it has accuracy compared to normal classification."],"metadata":{"id":"ErjHVAz8ulfc"}},{"cell_type":"markdown","source":["model_1.summary()"],"metadata":{"id":"oWjQWBYWtTv3"}},{"cell_type":"markdown","source":["# Binary classification\n","\n","1. visualize the data\n","2. preprocess the data(scaling / normalizing)\n","3. Create a model(start with a baseline)\n","4. Fit the model\n","5. Evaluate the model\n","6. Adjust the different parameters and improve the model.\n","7. twerk with the model to get better results"],"metadata":{"id":"WnOtxGVCwF0q"}},{"cell_type":"markdown","source":["# 1. Visualize the data\n"],"metadata":{"id":"Bz0furgUw7Fo"}},{"cell_type":"code","source":["plt.figure()\n","plt.subplot(1,2,1)\n","steak_img = view_random_image(\"pizza_steak/train/\", \"steak\")\n","\n","plt.subplot(1,2,2)\n","steak_img = view_random_image(\"pizza_steak/train/\", \"pizza\")\n"],"metadata":{"id":"tDMBhSW7w5tt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Preprocess the data(prepare it for a model)"],"metadata":{"id":"UMEguDw1x8JA"}},{"cell_type":"code","source":["#Define directory dataset paths\n","\n","train_dir = \"pizza_steak/train/\"\n","test_dir = \"pizza_steak/test/\""],"metadata":{"id":"qwDdD78vyM6s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["next step is to turn the data into\n","**batches**\n","\n","A batch is a small subset of data. Rather than look at all -10000 images at one time, a model might only look at 32 at a time.\n","\n","It does this for a couple of reasons:\n","1. 10,000 image(or more) might not fit into the memory of the processor(GPU).\n","\n","2. Trying to learn patterns in 10,000 images in one hit could result in the model not being able to learn patterns very well.\n","\n","3. Training batch size of more than 32 can result in test errors."],"metadata":{"id":"3AdL-RycyZ3G"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"K8T0Cy3by_d-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create train and test data generators and rescale the data.\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale = 1/255.)\n","test_datagen = ImageDataGenerator(rescale = 1/255.)"],"metadata":{"id":"vffk-R5Jz4Yt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load in our image data from the directories and turn them into batches\n","train_data = train_datagen.flow_from_directory(directory = train_dir, #Target directory of images\n","                                               target_size =(224,224),#Target size of images(height,width)\n","                                               class_mode = \"binary\",#type of data you're working with what type classification it could be.\n","                                               batch_size = 32 # size of minibatches to load data into\n","                                               )\n","test_data = train_datagen.flow_from_directory(directory = test_dir,\n","                                               target_size =(224,224),\n","                                               class_mode = \"binary\",\n","                                               batch_size = 32\n","                                               )"],"metadata":{"id":"DZzwCFGecLL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get a sample of a train data batch\n","images , labels = next(train_data)\n","len(images),len(labels)\n"],"metadata":{"id":"ybhd-nALd0J-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images.shape,labels.shape"],"metadata":{"id":"ZPS66di5eOr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#How many batches are there?\n","len(train_data)\n"],"metadata":{"id":"SDrtxyodeVkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1500/32"],"metadata":{"id":"Gy_mX1LWefqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get the first two images\n","images[:2],images[0].shape"],"metadata":{"id":"C2zM0Lv3e1P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images[7]"],"metadata":{"id":"rEGaZtTWgvpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images[:2].shape"],"metadata":{"id":"ykqk9tHjhAEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#view the first batch of labels\n","labels"],"metadata":{"id":"CUkd8Z1KhE07"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.Create a CNN model\n","\n","It is a relatively simple model or existing result (try to beat the baseling through the experimentation)"],"metadata":{"id":"BYvAX8YrheWu"}},{"cell_type":"code","source":["# Make the creating of our model easier\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Activation\n","from tensorflow.keras import Sequential\n"],"metadata":{"id":"L8HjwSu5hQJI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the model\n","model_4 = Sequential([\n","    Conv2D(filters =10,\n","           kernel_size =3, #same as (3,3) it is the size of the sliding window going across the image\n","           strides = 1, # the size of steps the sliding window takes across the iage\n","           padding = \"valid\",# If 'same\n","           activation = \"relu\",\n","           input_shape = (224,224,3)), # input layer(specify input shape)\n","    Conv2D(10,3,activation = \"relu\"),\n","    Conv2D(10,3,activation = \"relu\"),\n","    #MaxPool2D(),\n","    Flatten(),\n","    Dense(1,activation = \"sigmoid\") #output layer (working with binary classificatio so only 1 output neuron)\n","])"],"metadata":{"id":"sEdrX0ushYAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compile the model\n","\n","model_4.compile(loss = 'binary_crossentropy',\n","                optimizer = Adam(),\n","                metrics = ['accuracy'])"],"metadata":{"id":"9AM8xdjcc4dq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_4.summary()"],"metadata":{"id":"qq6s2gQ3dIUp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Fit the model"],"metadata":{"id":"9khKFXnzddi9"}},{"cell_type":"code","source":["#check the lengths of training and test data generators\n","len(train_data),len(test_data)"],"metadata":{"id":"DXCfoA7IdaFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fit the model\n","\n","history_4 = model_4.fit(train_data, # this is the combination of labels(y) and sample data(x)\n","epochs = 5,\n","                        steps_per_epoch = len(train_data)-1,\n","                        validation_data = test_data,\n","                        validation_steps = len(test_data)-1,\n","\n","                        )"],"metadata":{"id":"wmo50svJduIC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, MaxPool2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler"],"metadata":{"id":"_gSg-uvF7sFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model_spl\n","\n","# Model Definition\n","model_v = Sequential([\n","    Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(10, 3, activation=\"relu\"),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Flatten(),\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","# Compile Model\n","model_v.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=Adam(learning_rate=0.001),\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Learning Rate Scheduler\n","def scheduler(epoch, lr):\n","    return lr * 0.9 if epoch > 2 else lr\n","\n","lr_scheduler = LearningRateScheduler(scheduler)\n","\n","# Train Model\n","history_v = model_v.fit(\n","    train_data,\n","    epochs=5,\n","    steps_per_epoch=len(train_data)-1,\n","    validation_data=test_data,\n","    validation_steps=len(test_data)-1,\n","    callbacks=[lr_scheduler]\n",")\n"],"metadata":{"id":"PsZeCvwEgtDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","dummy_images = np.random.rand(10, 224, 224, 3).astype(np.float32)\n","dummy_labels = np.random.randint(0, 2, size=(10,)).astype(np.float32)\n","\n","result = model_4.train_on_batch(dummy_images, dummy_labels)\n","print(\"Dummy data test result:\", result)\n"],"metadata":{"id":"D5KbWGXLhaij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_1.evaluate(test_data)"],"metadata":{"id":"vT0duPXreml3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_1.summary()"],"metadata":{"id":"uf6PWr7jetRw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Evaluating our model"],"metadata":{"id":"5eCDvwaJe7rR"}},{"cell_type":"code","source":["history_4.history"],"metadata":{"id":"lig-1GVSjL7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","pd.DataFrame(history_4.history).plot(figsize=(10,7))"],"metadata":{"id":"_JqeXJWMe4__"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot the validation and training curves separately\n","\n","def plot_loss_curves(history):\n","  \"\"\"\n","  Returns separate loss curves for training and validation metrics.\n","  \"\"\"\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  accuracy = history.history['accuracy']\n","  val_accuracy = history.history['val_accuracy']\n","\n","  epochs = range(len(history.history['loss']))\n","\n","  # Plot loss\n","  plt.plot(epochs, loss, label='training_loss')\n","  plt.plot(epochs, val_loss, label='val_loss')\n","  plt.title('loss')\n","  plt.xlabel('Epochs')\n","  plt.legend()\n","\n","  # Plot accuracy\n","  plt.figure()\n","  plt.plot(epochs, accuracy, label='training_accuracy')\n","  plt.plot(epochs, val_accuracy, label='val_accuracy')\n","  plt.title('Accuracy')\n","  plt.xlabel('Epochs')\n","  plt.legend()"],"metadata":{"id":"2AqVgRRmkrqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check out the loss and accuracy of model_4\n","plot_loss_curves(history_4)"],"metadata":{"id":"FLL2XG_xlVkQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If a model's **validation loss** starts to increase, it's likely that the model is **Overfitting** the training dataset(It learning patterns in the training dataset too well thus diminishing the model's ability to generalize to unseen data)."],"metadata":{"id":"nMkV7tSSm0Eo"}},{"cell_type":"markdown","source":["# 6. Adjust the model parameters\n","\n","Fitting a machine learning model comes in 3 steps;\n","\n","1. create a baseline\n","2. beat the baseline by overfitting a larger model\n","3. reduce overfitting\n","\n","ways to induce overfitting\n","\n","* Increase the number of conv layers\n","* Increase the number of conv filters\n","* Add another dense layer to the output of our flattened layer\n","\n","Reduce Overfitting:\n","\n","* Add data augmentation\n","* Add regularization layers(maxpool2d etc,)\n","* Add more data..."],"metadata":{"id":"gYvpjDhBoB5I"}},{"cell_type":"code","source":["# Create the model (this )\n","model_5 = tf.keras.Sequential([\n","    Conv2D(10,3,activation = \"relu\",input_shape= (224,224,3)),\n","    MaxPool2D(pool_size = 2),\n","    Conv2D(10,3,activation = \"relu\"),\n","    MaxPool2D(),\n","    Conv2D(10,3,activation = \"relu\"),\n","    MaxPool2D(),\n","    Flatten(),\n","    Dense(1,activation = \"sigmoid\")\n","])"],"metadata":{"id":"k9AlBs1-nhH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compile the model\n","\n","model_5.compile(loss = 'binary_crossentropy',\n","                optimizer = Adam(),\n","                metrics = ['accuracy'])"],"metadata":{"id":"kc-7-idYfCB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fit the model\n","history_5 = model_5.fit(train_data,\n","                epochs = 5,\n","                steps_per_epoch = len(train_data)-1,\n","                validation_data = test_data,\n","                validation_steps = len(valid_data)-1)"],"metadata":{"id":"l6M11EzOn9YZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_5.summary()"],"metadata":{"id":"AXT2QBZjfUiZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_4.summary()"],"metadata":{"id":"Dio3Kf9bfcF7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot loss curves\n","plot_loss_curves(history_5)"],"metadata":{"id":"TclFhOdsfgvw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Augmentation.\n","\n","It is the process of altering our training data, leading it ot have more diversity and in turn allowing our models to learn more generalizable patterns. Altering might mean adjusting the rotaintion of an image, flipping it, cropping it or something similar.\n"],"metadata":{"id":"3mKSpNqBfz8o"}},{"cell_type":"code","source":["#create ImageGenerator training instance with\n","train_datagen_augmented = ImageDataGenerator(rescale = 1/255.,\n","                                             rotation_range = 0.2, #how much do you rotate an image.\n","                                             shear_range = 0.2, # how much do you want to shear an image.\n","                                             zoom_range = 0.2, # zoom in randomly on an image\n","\n","                                             width_shift_range = 0.2, #moves image around on the x-axis\n","                                             height_shift_range = 0.3, #moves image aroung on the y-axis\n","                                             horizontal_flip = True) #flips the image.\n","# Create ImageDataGenerator without data augmentation\n","train_datagen = ImageDataGenerator(rescale = 1/255.)\n","\n","# Create ImageGenerator without data augmentation for the test dataset\n","test_datagen = ImageDataGenerator(rescale = 1/255.)"],"metadata":{"id":"PWVUDL-vper5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import data and augment it from training data.\n","print(\"Augmented training images\")\n","train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n","                                                                   target_size = (224,224),\n","                                                                   batch_size = 32,\n","                                                                   class_mode = \"binary\",\n","                                                                   shuffle = False\n","                                                                  )\n","\n","#create non-augmented train data batches\n","print(\"Non-augmented training images\")\n","test_data = train_datagen.flow_from_directory(train_dir,\n","                                              target_size = (224,224),\n","                                              batch_size =32,\n","                                              class_mode = \"binary\",\n","                                              shuffle = False)\n","#Create non-augmented test data batches\n","print(\"Non-augmented test images\")\n","test_data = test_datagen.flow_from_directory(test_dir,\n","                                             target_size = (224,224),\n","                                             batch_size = 32,\n","                                             class_mode = \"binary\",\n","                                             shuffle = False)\n"],"metadata":{"id":"jAuzxtC-qPsr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data augmentation is only performed on the training data.\n","\n","using the **ImageDataGenerator** the built-in data augmentation parameters our images are left as they are in the directories but are modified as they're loaded into the model.\n"],"metadata":{"id":"4h3N7Bqe3U9e"}},{"cell_type":"markdown","source":["# Visualizing the Augmented data"],"metadata":{"id":"AI3-rrGM39Bc"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import random\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n"],"metadata":{"id":"daWVqchkzBfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create ImageDataGenerator for data augmentation\n","train_datagen_augmented = ImageDataGenerator(\n","    rescale=1/255.,\n","    rotation_range=0.2,  # Rotate the image\n","    shear_range=0.2,  # Shear the image\n","    zoom_range=0.2,  # Zoom in/out on the image\n","    width_shift_range=0.2,  # Shift the image horizontally\n","    height_shift_range=0.3,  # Shift the image vertically\n","    horizontal_flip=True  # Flip the image horizontally\n",")\n","\n","# Create ImageDataGenerator for non-augmented data (training and testing)\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","test_datagen = ImageDataGenerator(rescale=1/255.)"],"metadata":{"id":"zWLNyCeMBCEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Import data and augment it from the training data\n","print(\"Augmented training images:\")\n","train_data_augmented = train_datagen_augmented.flow_from_directory(\n","    train_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode=\"binary\",\n","    shuffle=False  # Ensure the same order of images for consistency\n",")\n","\n","# Create non-augmented training data batches\n","print(\"Non-augmented training images:\")\n","train_data = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode=\"binary\",\n","    shuffle=False  # Ensure the same order of images for consistency\n",")\n","\n","# Create non-augmented testing data batches\n","print(\"Non-augmented test images:\")\n","test_data = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode=\"binary\",\n","    shuffle=False\n",")\n"],"metadata":{"id":"EmgrdbetBE5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Fetch a batch of original and augmented images\n","original_images, labels = next(train_data)  # Non-augmented images\n","augmented_images, augmented_labels = next(train_data_augmented)  # Augmented images\n","\n","# Ensure batch size consistency\n","assert len(original_images) == len(augmented_images), \"Mismatch in batch sizes!\"\n","\n","# Randomly select an image from the batch\n","random_number = random.randint(0, len(original_images) - 1)\n","print(f\"Showing image number: {random_number}\")\n","\n","# Display the original image\n","plt.figure(figsize=(8, 4))\n","plt.subplot(1, 2, 1)\n","plt.imshow(original_images[random_number])\n","plt.title(\"Original Image\")\n","plt.axis(False)\n","\n","# Display the corresponding augmented image\n","plt.subplot(1, 2, 2)\n","plt.imshow(augmented_images[random_number])\n","plt.title(\"Augmented Image\")\n","plt.axis(False)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"CswN67y1BO6u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating the model with augmented data\n"],"metadata":{"id":"JpXTjJx1Bciv"}},{"cell_type":"code","source":["# Create a model(same as model_5)\n","model_6 = Sequential([\n","    Conv2D(10,3,activation = \"relu\"),\n","    MaxPool2D(pool_size =2),\n","    Conv2D(10,3,activation = \"relu\"),\n","    MaxPool2D(),\n","    Conv2D(10,3,activation = \"relu\"),\n","    MaxPool2D(),\n","    Flatten(),\n","    Dense(1,activation=\"sigmoid\")\n","\n","])\n","\n","#compile the moedl\n","\n","model_6.compile(loss = \"binary_crossentropy\",\n","                optimizer = Adam(),\n","                metrics = [\"accuracy\"])\n","\n","# Fit the model\n","history_6 = model_6.fit(train_data_augmented,epochs=5,\n","                        steps_per_epoch = len(train_data_augmented)-1,\n","                        validation_data = test_data,\n","                        validation_steps = len(test_data)-1)\n","\n","# It takes more time as it the data flows in the data gets augmented which takes more time.\n"],"metadata":{"id":"oGGH_sWOMpjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Check our models training curves\n","history_6.history\n","#plot_loss_curves(history_6)"],"metadata":{"id":"xtxNxVe3cD-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_loss_curves(history_6)"],"metadata":{"id":"aObZFIl6cfOc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's shuffle our augmented training data and train another model same as before."],"metadata":{"id":"dwzHRiIzdJkt"}},{"cell_type":"code","source":["#Import data and augment it and then shuffle from training directory.\n","train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n","                                                                            target_size = (224,224),\n","                                                                            class_mode= \"binary\",\n","                                                                            batch_size =32,\n","                                                                            shuffle = True)"],"metadata":{"id":"BcONsfGNPfyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create the model.\n","# Create a model(same as model_5)\n","model_7 = Sequential([\n","    Conv2D(10,3,activation = \"relu\",input_shape = (224,224,3)),\n","    MaxPool2D(pool_size =2),\n","    Conv2D(10,3,activation = \"relu\"),\n","    MaxPool2D(),\n","    Conv2D(10,3,activation = \"relu\"),\n","    MaxPool2D(),\n","    Flatten(),\n","    Dense(1,activation=\"sigmoid\")\n","\n","])\n","\n","#compile the moedl\n","\n","model_7.compile(loss = \"binary_crossentropy\",\n","                optimizer = Adam(),\n","                metrics = [\"accuracy\"])\n","\n","# Fit the model\n","history_7 = model_7.fit(train_data_augmented_shuffled,epochs=5,\n","                        steps_per_epoch = len(train_data_augmented_shuffled)-1,\n","                        validation_data = test_data,\n","                        validation_steps = len(test_data)-1)\n","\n","# It takes more time as it the data flows in the data gets augmented which takes more time.\n","\n"],"metadata":{"id":"x_YEOZvKjJyG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plot loss curves\n","plot_loss_curves(history_7)"],"metadata":{"id":"CXrR83o-j7wk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When shuffleing the training data, the model gets exposed to all different kinds of data during training, thus enabling it learn features across wide array of images.\n"],"metadata":{"id":"r_jlviBckl8r"}},{"cell_type":"markdown","source":["* Increase the number of model layers(e.g add more 'Conv2D'/ 'MaxPool2D' layers)   \n","\n","* Increase the number of filters in each convolutional layer\n","\n","* Train for longer (more epochs)\n","\n","* Find an ideal learning rate\n","\n","* Get more data\n","\n","* Use **transfer learning** to leverage what another image model has learn and adjust it for our own use case."],"metadata":{"id":"MmFGPC1MlCS_"}},{"cell_type":"markdown","source":["# Make a prediction with our trained model on our own custom data."],"metadata":{"id":"Y41BJqKH9Wax"}},{"cell_type":"code","source":["print(class_names)"],"metadata":{"id":"1BQKqZsJ8yp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://www.istockphoto.com/photo/grilling-steaks-on-flaming-grill-and-shot-with-selective-focus-gm594465522-101933167"],"metadata":{"id":"bwG09sDu_m2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#view our example image\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","# import a file from your desktop named 03-steak.jpeg and continue with below code for visualizing.\n","steak = mpimg.imread(\"steak_img.jpg\")\n","plt.imshow(steak)\n","plt.axis(False)"],"metadata":{"id":"WtKr3Kyx9h3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["steak.shape"],"metadata":{"id":"BCFbV3lz-3zX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["when you train a neural network and you want make a prediction with it on you own custom data, it's important that the custom data is preprocessed into the same format as the data the model was trained on."],"metadata":{"id":"PTDlIdKQF0ZR"}},{"cell_type":"code","source":["# Create a function to import an image and resize it to be able to be used with the model.\n","def load_and_prep_image(filename, img_shape=224):\n","  \"\"\"\n","  Reads an image from filename, turns it into a tensor and reshapes it to\n","  (img_shape, img_shape, colour_channel).\n","  \"\"\"\n","  # read in the image\n","  img = tf.io.read_file(filename)\n","  # Decode the read file into a tensor & ensure 3 colour channels\n","  # (our model is trained on images with 3 colour channels\n","\n","  img = tf.image.decode_image(img)\n","\n","  #resize the image\n","  img = tf.image.resize(img,size = [img_shape,img_shape])\n","\n","  #rescale the image (get all values between 0 and 1)\n","  img = img/255.\n","  return img"],"metadata":{"id":"JVB58ObOFzpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load in and preprocess our custom image\n","steak = load_and_prep_image(\"steak_img.jpg\")"],"metadata":{"id":"APdWosF-IRSu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This expands the dimension to pass in the batch size of the input as the model expects it.\n","expanded_steak = tf.expand_dims(steak,axis = 0)\n","expanded_steak.shape"],"metadata":{"id":"9oCJUvzlFbwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = model_7.predict(expanded_steak)"],"metadata":{"id":"tM2V5mOaFFZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we can index the predicted class by rounding the prediction probability\n","pred_class = class_names[int(tf.round(pred))]\n","pred_class\n"],"metadata":{"id":"PRaZFsMTMVKW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pred_and_plot(model,filename,class_names=class_names):\n","  \"\"\"\n","\n","  imports an image located at the file name, makes a prediction with model and plots\n","  the image with predicted class as the title. \"\"\"\n","\n","  # import the target image and preprocess it\n","  img = load_and_prep_image(filename)\n","\n","  # add an extra dimension to the image\n","  img_expanded = tf.expand_dims(img,axis = 0)\n","\n","  # make a prediction\n","  pred = model.predict(img_expanded)\n","\n","  # Get the predicted class\n","  pred_class = class_names[int(tf.round(pred))]\n","\n","  # Plot the image and predicted class\n","  plt.imshow(img)\n","  plt.title(f\"Prediction: {pred_class}\")\n","  plt.axis(False)"],"metadata":{"id":"u7nkHreZQwhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Test  our model on a custom image\n","pred_and_plot(model_7,\"steak_img.jpg\")"],"metadata":{"id":"8fadNJ7LYyjh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://ohsweetbasil.com/wp-content/uploads/how-to-make-authentic-margherita-pizza-at-home-recipe-4.jpg"],"metadata":{"id":"SlK9koXCZvIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_and_plot(model_7,\"xyz.jpg\")"],"metadata":{"id":"GTyicUOJZ2Do"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Multi-class classification\n","\n","1. Become one with the data\n","2. preprocess the data (get it ready for a model)\n","3. Create a model (start with a baseline)\n","4. Fit the model.(overfit to make sure it works)\n","5. Evaluate the model.\n","6. Adjust different hyperparameters and improve the model(try to beat baseline/ reduce overfitting)\n","7. Repeat until satisfied"],"metadata":{"id":"_9BbndaB2AF_"}}]}