{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOj8ajpAakOYYvqSFe7Plxh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Transfer Learning with Tensorflow Part 1: Feature Extraction\n","\n"," Transfer learnin is leveraging a working model's existing architecture and learned patterns\n"," for our own problem.\n","\n"," 2 benefits\n"," 1. can leverage existing neural network architecture proven to work on to our own.\n"," 2. can leverage a working neural network architecute which has already learned patterns on\n"," similalr data to our own, then we can adapt those patterns to our own data.\n","  "],"metadata":{"id":"YpTMOQs_MIpA"}},{"cell_type":"code","source":["# Are we using a gpu?\n","!nvidia-smi\n"],"metadata":{"id":"XP0hYV7BNktr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Downloading and becoming one with the data"],"metadata":{"id":"DrKzk3x3NxHm"}},{"cell_type":"code","source":["#Get data(10% of 10 food classes from food101)\n","\n","import zipfile\n","\n","#Download the data\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"],"metadata":{"id":"IsTD2Eh7N-00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#unzip the downladed file\n","zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\",\"r\")\n","zip_ref.extractall()\n","zip_ref.close()"],"metadata":{"id":"VVN8BhJrtUZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#How many images in each folder?\n","\n","import os\n","\n","# Walk thr0ugh 10 percent data directory and list nuber of files\n","for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"],"metadata":{"id":"KCqsEsrQuAwl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creating data loaders(preparing the data)\n","we'll use the `ImageDataGenerator` class to load in our images in batches."],"metadata":{"id":"1YKU57A5ugJ1"}},{"cell_type":"code","source":["#Setup data inputs\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Hyperparameters\n","IMAGE_SHAPE = (224,224)\n","BATCH_SIZE = 32\n","\n","\n","train_dir = \"10_food_classes_10_percent/train/\"\n","test_dir = \"10_food_classes_10_percent/test/\"\n","\n","train_datagen = ImageDataGenerator(rescale = 1/255.)\n","test_datagen = ImageDataGenerator(rescale = 1/255.)"],"metadata":{"id":"DrtBq1d7wwDm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Training images:\")\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n","                                                          target_size = IMAGE_SHAPE,\n","                                                          batch_size = BATCH_SIZE,\n","                                                          class_mode = \"categorical\")\n","print(\"testing images:\")\n","test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n","                                                          target_size = IMAGE_SHAPE,\n","                                                          batch_size = BATCH_SIZE,\n","                                                          class_mode = \"categorical\")\n"],"metadata":{"id":"0wbay-2BxMaF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting up callbacks (things to run whilst our model trains)\n","\n","Callbacks are extra functiionality you can add to your models to be performed during or after training. Some of the most popular callbacks:\n","\n","* Tracking experiments with the TensorBoard callback\n","\n","* Model checkpoint with the ModelCheckpoint callback\n","\n","* Stopping a model from training (before it training too long and overfits) with the EarlyStopping callback"],"metadata":{"id":"XkZzgk0Pxm6v"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"QpVnwb3mANt3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create TensorBoard callback (funtionized because we need to creae a new one for each model)\n","import datetime\n","\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback"],"metadata":{"id":"XM-hUXoYx79u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import datetime\n","import os\n","\n","def create_tensorboard_callback(dir_name, experiment_name):\n","    \"\"\"Creates a TensorBoard callback that logs training metrics to a directory.\"\"\"\n","\n","    # Ensure directory exists\n","    log_dir = os.path.join(dir_name, experiment_name, datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\"))\n","    os.makedirs(log_dir, exist_ok=True)  # Create directory if it doesn't exist\n","\n","    # Create TensorBoard callback\n","    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","\n","    print(f\" Saving TensorBoard logs to: {log_dir}\")\n","    return tensorboard_callback\n"],"metadata":{"id":"UFjJzgIpIzE_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note: You can customize the directory where your TensorBoard logs (model training metrics )\n","saved to whatever you like. The log_dir parameter we've created above is only one option."],"metadata":{"id":"lVZYEd2H_P7X"}},{"cell_type":"markdown","source":["## Creating models using TensorFlow Hub\n","\n","In the past we've used TensorFlow to create our own models layer by layer from scratch.\n","\n","Now we're going to do similar process, except the majority are used from teh TensorFlow HUb.\n","\n","we access models using : https://tfhub.dev/\n","\n","This the feature vector model that we are using. https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-classification/1"],"metadata":{"id":"n42UbeNaI2oW"}},{"cell_type":"code","source":["resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n","efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n"],"metadata":{"id":"4jsaxRxgI9eK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow_hub --upgrade  #Upgrade TensorFlow Hub to the latest version\n","!pip install --upgrade tensorflow     #Upgrade Tensorflow to the latest version"],"metadata":{"id":"YuFq9YksT4Y6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers\n","\n","# Create a custom wrapper class for the hub.KerasLayer\n","class HubLayerWrapper(layers.Layer):\n","    def __init__(self, model_url, **kwargs):\n","        super(HubLayerWrapper, self).__init__(**kwargs)\n","        self.model_url = model_url\n","\n","    def build(self, input_shape):\n","        self.hub_layer = hub.KerasLayer(self.model_url, trainable=False)\n","        self.hub_layer.build(input_shape)\n","        super(HubLayerWrapper, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        return self.hub_layer(inputs)\n","\n","def create_model(model_url, num_classes=10):\n","    \"\"\"\n","    Create a model with TensorFlow Hub's feature extraction layer and a custom classification head.\n","\n","    Args:\n","        model_url (str): A TensorFlow Hub feature extraction URL.\n","        num_classes (int): Number of output neurons in the output layer.\n","\n","    Returns:\n","        A Keras model.\n","    \"\"\"\n","\n","\n","    # Input layer\n","    inputs = layers.Input(shape=(224, 224, 3))\n","\n","    # Feature extraction using the custom HubLayerWrapper\n","    feature_extractor = HubLayerWrapper(model_url)(inputs)\n","\n","    # Classification layer\n","    outputs = layers.Dense(num_classes, activation='softmax', name=\"output_layer\")(feature_extractor)\n","\n","    # Create and return the model\n","    model = tf.keras.Model(inputs, outputs)\n","\n","    return model\n"],"metadata":{"id":"5fEH34tsLBRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers\n","\n","# Optimized Hub Layer Wrapper\n","class HubLayerWrapper(layers.Layer):\n","    def __init__(self, model_url, trainable=False, **kwargs):\n","        super(HubLayerWrapper, self).__init__(**kwargs)\n","        self.hub_layer = hub.KerasLayer(model_url, trainable=trainable)  # Initialize once\n","\n","    def call(self, inputs):\n","        return self.hub_layer(inputs)  # Directly call the hub layer\n"],"metadata":{"id":"YsQ8OAbY0ptW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model(model_url, num_classes=10):\n","    \"\"\"\n","    Create a model with TensorFlow Hub's feature extraction layer and a classification head.\n","\n","    Args:\n","        model_url (str): A TensorFlow Hub feature extraction URL.\n","        num_classes (int): Number of output neurons in the output layer.\n","\n","    Returns:\n","        A Keras model.\n","    \"\"\"\n","\n","    # Input layer\n","    inputs = layers.Input(shape=(224, 224, 3))\n","\n","    # Feature extraction using the optimized wrapper\n","    feature_extractor = HubLayerWrapper(model_url, trainable=False)(inputs)\n","\n","    # Classification layer\n","    outputs = layers.Dense(num_classes, activation='softmax', name=\"output_layer\")(feature_extractor)\n","\n","    # Create and return the model\n","    model = tf.keras.Model(inputs, outputs)\n","\n","    return model\n"],"metadata":{"id":"C-iJjQaL0spV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","# Define input\n","inputs = tf.keras.Input(shape=(224, 224, 3), dtype=tf.float32)\n","\n","# Load TensorFlow Hub Layer\n","hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5\", trainable=False)\n","\n","print(hub_layer.get_config())\"\"\""],"metadata":{"id":"ArDc8pr1Cv4A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"dummy_input = tf.ones((1, 224, 224, 3))  # Batch size 1\n","output = hub_layer(dummy_input)\n","print(\"Output shape:\", output.shape)\"\"\""],"metadata":{"id":"JKcsK-MXF7LQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"inputs = tf.keras.Input(shape=(224, 224, 3), dtype=tf.float32)\"\"\""],"metadata":{"id":"0KJu9RoFGHNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"print(inputs.shape)    \"\"\""],"metadata":{"id":"RcwwgVBaGfDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers\n","\n","# Define a wrapper for the TensorFlow Hub layer\n","class HubLayerWrapper(tf.keras.layers.Layer):\n","    def __init__(self, model_url, **kwargs):\n","        super(HubLayerWrapper, self).__init__(**kwargs)\n","        self.model_url = model_url\n","        self.feature_extractor_layer = hub.KerasLayer(model_url, trainable=False, name=\"feature_extraction_layer\")\n","\n","    def build(self, input_shape):\n","        self.feature_extractor_layer.build(input_shape)\n","\n","    def call(self, inputs):\n","        return self.feature_extractor_layer(inputs)\n","\n","# Define the function to create the model\n","def create_model(model_url, num_classes=10):\n","\n","    #Creates a Keras Sequential model using a TensorFlow Hub feature extractor.\n","\n","    #Args:\n","    #model_url (str): URL of the TensorFlow Hub model.\n","    #num_classes (int): Number of classes for classification.\n","\n","    #Returns:\n","    #tf.keras.Sequential: A compiled Keras model.\n","\n","    feature_extractor_layer = HubLayerWrapper(model_url, input_shape=(224, 224, 3))\n","\n","    model = tf.keras.Sequential([\n","        feature_extractor_layer,\n","        layers.Dense(num_classes, activation='softmax', name=\"output_layer\")\n","    ])\n","\n","    return model\n","\n","# Example usage\n","model_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n","resnet_model = create_model(model_url, num_classes=10)\n","\n","# Print model summary\n","#resnet_model.build((None, 224, 224, 3))  # Ensure correct input shape\n","resnet_model.summary()\n","\"\"\"\n","\n","#gives the same function as above\n"],"metadata":{"id":"0Pc9BKCAOqQP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating and testing ResNet TensorFlow Hub Feature Extraction model"],"metadata":{"id":"29rq877kSuED"}},{"cell_type":"code","source":["\n","# Define the URL for ResNet or any other model you want to use from TensorFlow Hub\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n","\n","# Create the model\n","resnet_model = create_model(resnet_url, train_data_10_percent.num_classes)\n","\n","# Print the model summary\n","resnet_model.summary()\n"],"metadata":{"id":"jo5UaOPjLo4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compile our resnet model\n","resnet_model.compile(loss = \"categorical_crossentropy\",\n","                     optimizer = tf.keras.optimizers.Adam(),\n","                     metrics = [\"accuracy\"])"],"metadata":{"id":"YE99Z-i_Pjcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_to_tf_dataset(directory_iterator, batch_size=32):\n","    return tf.data.Dataset.from_generator(\n","        lambda: directory_iterator,\n","        output_signature=(\n","            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n","            tf.TensorSpec(shape=(None,), dtype=tf.int32)\n","        )\n","    ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","# Convert train and test datasets\n","train_data_10_percent = convert_to_tf_dataset(train_data_10_percent)\n","test_data_10_percent = convert_to_tf_dataset(test_data_10_percent)\n","\n","# Resize images\n","def resize_images(batch_images, label):\n","    # Ensure batch_images is 4D (batch_size, height, width, channels)\n","    print(batch_images.shape)  # Check if the shape is (batch_size, height, width, channels)\n","    resized_images = tf.image.resize(batch_images, (224, 224))\n","    print(resized_images.shape)  # After resize (batch_size, 224, 224, 3)\n","    return resized_images, label\n","\n","# Apply the map function for resizing images\n","train_data_10_percent = train_data_10_percent.map(resize_images, num_parallel_calls=tf.data.AUTOTUNE)\n","test_data_10_percent = test_data_10_percent.map(resize_images, num_parallel_calls=tf.data.AUTOTUNE)\n"],"metadata":{"id":"jRUhKnp1CAXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fit the resnet model to the data\n","resnet_history = resnet_model.fit(train_data_10_percent,\n","                                  epochs =5,\n","                                  steps_per_epoch = len(train_data_10_percent)-1,\n","                                  validation_data = test_data_10_percent,\n","                                  validation_steps= len(test_data_10_percent)-1,\n","                                  callbacks = [create_tensorboard_callback(dir_name =\"tensorflow_hub\",\n","                                                                           experiment_name=\"resnet50v1\")])\n",""],"metadata":{"id":"uKzdXFBly_j8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#funtion to plot loss curves..\n","import matplotlib.pyplot as plt\n","\n","#PLT THE VALIDATION AND TRAINING CURVES\n","\n","def plot_loss_curves(history):\n","  \"\"\"\n","  returns separate loss curves for training and validation metrics.\n","\n","  Args:\n","  history: TensorFlow History object.\n","\n","  Returns:\n","  Plots of training/validation loss and accuracy metrics.\n","  \"\"\"\n","  loss = history.history[\"loss\"]\n","  val_loss = history.history[\"val_loss\"]\n","\n","  accuracy = history.history[\"accuracty\"]\n","  val_accuracy = history.history[\"val_accuracy\"]\n","\n","  epochs = range(len(history.history[\"loss\"]))\n","\n","  # Plot loss\n","  plt.plot(epochs, loss, label= \"training_loss\")\n","  plt.plot(epochs, val_loss, label = \"val_loss\")\n","  plt.title(\"Loss\")\n","  plt.xlabel(\"Epochs\")\n","  plt.legend()\n","\n","  # Plot accuracy\n","  plt.figure()\n","  plt.plot(epochs, accuracy, label = \"training_accuracy\")\n","  plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n","  plt.title(\"Accuracy\")\n","  plt.xlabel(\"Epochs\")\n","  plt.legend();"],"metadata":{"id":"7dyaVTfBy32a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#function call\n","plot_loss_curves(resnet_history)"],"metadata":{"id":"i9WHAXvy9w-8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creating and testing EfficientNetB0 TensorFlow Hub Feature Extraction model.\n"],"metadata":{"id":"6i8G_fdO_Bdt"}},{"cell_type":"code","source":["#Create EfficientNetB0 feature extractor model\n","efficient_model = create_model(efficientnet_url, num_classes = train_data_10_percent.num_classes)\n","\n","#Compile the model\n","efficient_model.compile(loss = \"categorical_crossentropy\",\n","                        optimizer = tf.keras.optimizers.Adam(),\n","                        metrics = [\"accuracy\"])\n"],"metadata":{"id":"ZPFEwZ7c_Oab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Fit EfficientNet model to the training data\n","efficient_history = efficient_model.fit(train_data_10_percent,\n","                                         epochs = 5,\n","                                         steps_per_epoch = len(train_data_10_percent),\n","                                         validation_data = test_data_10_percent,\n","                                         validation_steps = len(test_data_10_percent),\n","                                         callbacks = [create_tensorboard_callback(dir_name = \"tensorflow_hub\",\n","                                                                                   experiment_name = \"efficientnetb0v1\")])"],"metadata":{"id":"FQGfKRgJAt7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#how many layers does our efficientnetb0 feature extractor have\n","len(efficientnet_model.layer[0].weights)"],"metadata":{"id":"UeH-yj4cND44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plotting loss curves\n","plot_loss_curves(efficient_history)"],"metadata":{"id":"EN0UjuN2BUWK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Different types of transfer learning\n","\n","* transfer learning - using an existing model with no changes\n","* Feature extraction transfer learning - use the prelearned patterns of existing model and adjust output layer for our own output.\n","* Fine-tuning transfer learning - use the prelearned patters of existing model and \"fine-tune\" many or all of the underlying layers(including output layer)"],"metadata":{"id":"1H35DRquLxTn"}},{"cell_type":"markdown","source":["# Comparing our models results using TensorBoard"],"metadata":{"id":"2L_rz8p8Oedl"}},{"cell_type":"code","source":["#upload TensorBoard dev records this will upload to tensorboard. (it is shutdown so no use)\n","!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n","--name \"EfficientNetB0 vs. ResNet50V2\" \\\n","--description \"Compareing two different TF Hub feature extraction model architecture using 10% training data\" \\\n","--one_shot"],"metadata":{"id":"Si8ao9xWOnsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tensorboard dev list"],"metadata":{"id":"nXWeSD0JQYja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#to delete\n","#!tensorboard dev delete --experiment_id (you specify id here without brackets)"],"metadata":{"id":"rfib7EK8Qdf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6kyb62leQuP8"},"execution_count":null,"outputs":[]}]}