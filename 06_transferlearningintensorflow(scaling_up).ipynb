{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyPc5FqHUsEOhuxlhMQ8tjay"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["#Transfer Learning with RensorFlow Part 3 : Scalingup\n","\n","(Food vision mini)\n","\n","we've seen the power of transfer learning feature extraction and fine-tuning\n",", now it's time to scale up to all of the classes in Food101\n"],"metadata":{"id":"GTxygllNl7KE"}},{"cell_type":"code","source":["#using the helper funtions\n","!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"],"metadata":{"id":"dMHrvjirmeKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import series of helper function from the helper.py module\n","from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"],"metadata":{"id":"XTfbbtb4mznB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 101 Food Classes: working with less data trying to beat original Food101 paper with 10% of the training data.\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip"],"metadata":{"id":"bigVzm80nJGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unzip_data(\"101_food_classes_10_percent.zip\")\n","train_dir = \"101_food_classes_10_percent/train/\"\n","test_dir = \"101_food_classes_10_percent/test/\""],"metadata":{"id":"uUiArf63oEAt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#walk through the directories\n","walk_through_dir(\"101_food_classes_10_percent\")"],"metadata":{"id":"yEy81gbYoEBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup data inputs\n","import tensorflow as tf\n","IMG_SIZE = (224, 224)\n","train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n","                                                                                  label_mode=\"categorical\",\n","                                                                                  image_size=IMG_SIZE)\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n","                                                                label_mode=\"categorical\",\n","                                                                image_size=IMG_SIZE,\n","                                                                shuffle = False)#don't shuffle test data for prediction analysis.\n"],"metadata":{"id":"cVcRAWcpooFo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train a big dog model with transfer learning on 10% of 101 food classes\n","\n","steps:\n","\n","* Create a ModelCheckpoint callback\n","* Create a data augmentation layer to build data aumentation right into the model\n","* Build a headless (no top layers) funtional EfficientNetB0 backboned-model\n","* compile our model\n","* Feature extract for 5 full passes(5 epochs on the train dataset and validate on 15% of the test data, to save epoch time)\n"],"metadata":{"id":"vK5hIBdqqsnj"}},{"cell_type":"code","source":["#create checkpoint callback\n","checkpoint_path = \"101_classes_10_percent_data_model_checkpoint.weights.h5\"\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n","                                                         save_weights_only=True,\n","                                                         monitor=\"val_accuracy\",\n","                                                         save_best_only=True)"],"metadata":{"id":"PtgX4-_Zrwab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create data augmentation layer to incorporate it\n","from tensorflow.keras import layers\n","from tensorflow.keras import preprocessing\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import RandomFlip,RandomRotation,RandomHeight,RandomWidth,RandomZoom\n","\n","data_augmentation = Sequential([\n","    RandomFlip(\"horizontal\"),\n","    RandomRotation(0.2),\n","    RandomHeight(0.2),\n","    RandomWidth(0.2),\n","    RandomZoom(0.2),\n","    #Rescaling(1/255.) we need to rescale for image classification using resnet efficientnet automatically makes it normalized\n","\n","],name=\"data_augmentation\")"],"metadata":{"id":"E3heOnUtsVe5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Setup the base model and freeze its layers (this will extract features)\n","base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n","base_model.trainable = False\n","\n","# Setup model architecture wth trainable top layers\n","inputs = layers.Input(shape=(224,224,3),name=\"input_layer\")\n","x = data_augmentation(inputs)#Augment images (happens during training phase)\n","x = base_model(x,training=False)#base model in inference mode so weights which need to stay frozen , stay frozen)\n","x = layers.GlobalAveragePooling2D(name = \"global_average_pooling_layer\")(x)\n","outputs = layers.Dense(len(train_data_all_10_percent.class_names),activation=\"softmax\",name=\"output_layer\")(x)\n","model = tf.keras.Model(inputs,outputs)\n"],"metadata":{"id":"MD_Vuaygtypu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(outputs)"],"metadata":{"id":"NxmtHl8JcNFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#summary of the model created\n","model.summary()"],"metadata":{"id":"DAupWYIdvE5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"6wtcmKilvMh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fit\n","history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n","                                           epochs = 5,# fit for 5 epochs basic\n","                                           validation_data = test_data,\n","                                           validation_steps = int(0.15 * len(test_data)),\n","                                           callbacks = [checkpoint_callback])"],"metadata":{"id":"FcH0n_4kvjx4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Evaluate on the whole test dataset\n","fine_tuneing_results = model.evaluate(test_data)\n","fine_tuneing_results"],"metadata":{"id":"KYnfORv9wQvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot loss curves\n","plot_loss_curves(history_all_classes_10_percent)"],"metadata":{"id":"xcETY0Htw5P_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Fine-tuning"],"metadata":{"id":"heYXswyow8nx"}},{"cell_type":"code","source":["#Unfreeze all of the layers in the base model\n","base_model.trainable = True\n","\n","#Refreeze every layer except last 5\n","for layer in base_model.layers[:-5]:\n","  layer.trainable = False"],"metadata":{"id":"mi66RQJsxWwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for layer in base_model.layers:\n","  print(layer.name, layer.trainable)"],"metadata":{"id":"gcjM8fHhxxh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Recompile model with lower learning rate (as it is better to lower learning rate after fine-tuning)\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(0.0001),\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"A09o0Grlx_tL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fine tune for 5 more epochs\n","fine_tune_epochs = 10 #model has already done 5 epochs (feature extraction), this is the total number of epochs including the previous training)\n","history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n","                              epochs = fine_tune_epochs,\n","                              validation_data = test_data,\n","                              validation_steps = int(0.15 * len(test_data)),\n","                              initial_epoch = history_all_classes_10_percent.epoch[-1],\n","\n",")"],"metadata":{"id":"Ffv5-jltyI6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#evaluate the model now\n","all_classes_10_percent_fine_tune = model.evaluate(test_data)\n","all_classes_10_percent_fine_tune"],"metadata":{"id":"6y6KeRG5zcFu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plotting loss curves\n","plot_loss_curves(history_all_classes_10_percent_fine_tune)"],"metadata":{"id":"g8uGNhN81f0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from helper_functions import compare_historys"],"metadata":{"id":"nI_iDmmC2BYG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compare the histories\n","compare_historys(original_history = history_all_classes_10_percent,\n","                  new_history = history_all_classes_10_percent_fine_tune,\n","                  initial_epochs = 5)"],"metadata":{"id":"LPC5mIOJz5Q1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Saving and loading our model\n","To use the model in an external application, we'll need to save it and export it"],"metadata":{"id":"ILAlT57a2cpp"}},{"cell_type":"code","source":["#save our fine-tuned model\n","model.save(\"drive/MyDrive/tensor_flow/101_food_classes_10_percent_data_model.keras\")"],"metadata":{"id":"wc9r5ETp2p7e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load model\n","load_model = tf.keras.models.load_model(\"drive/MyDrive/tensor_flow/101_food_classes_10_percent_data_model.keras\")"],"metadata":{"id":"OogXf1Ww4UZo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#evaluate loaded model and compare performance to pre-saved model\n","loaded_model_results = load_model.evaluate(test_data)\n","loaded_model_results"],"metadata":{"id":"IaP5Vpw74hzK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#The results from the model before it is saved\n","\n","all_classes_10_percent_fine_tune\n"],"metadata":{"id":"AHziiXO04tuw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# New model"],"metadata":{"id":"qpFDR7M_ECQf"}},{"cell_type":"code","source":["import tensorflow as tf\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip\n"],"metadata":{"id":"t5TwYr6sE1Hg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#using the helper funtions\n","!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"],"metadata":{"id":"R1h1pYCCICTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from helper_functions import unzip_data"],"metadata":{"id":"8-TDZvZcHyzf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unzip_data(\"/content/06_101_food_class_10_percent_saved_big_dog_model.zip\")"],"metadata":{"id":"THUvDA9zE47I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 101 Food Classes: working with less data trying to beat original Food101 paper with 10% of the training data.\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip"],"metadata":{"id":"LWgJDmTcYYVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unzip_data(\"101_food_classes_10_percent.zip\")"],"metadata":{"id":"_QkgSWmtYbMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = \"101_food_classes_10_percent/train/\"\n","test_dir = \"101_food_classes_10_percent/test/\""],"metadata":{"id":"eOLygs4RYGMZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup data inputs\n","import tensorflow as tf\n","IMG_SIZE = (224, 224)\n","train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n","                                                                                  label_mode=\"categorical\",\n","                                                                                  image_size=IMG_SIZE)\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n","                                                                label_mode=\"categorical\",\n","                                                                image_size=IMG_SIZE,\n","                                                                shuffle = False)#don't shuffle test data for prediction analysis.\n"],"metadata":{"id":"2m3foGZ-Xv27"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Load the old model using TFSMLayer (Inference-only)\n","base_model2 = tf.keras.layers.TFSMLayer(\n","    \"/content/06_101_food_class_10_percent_saved_big_dog_model\",  # Replace with your model path\n","    call_endpoint=\"serving_default\"  # Replace with the correct endpoint if necessary\n",")\n","\n","\n"],"metadata":{"id":"80YEDSH6EcEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define inputs\n","inputs = tf.keras.Input(shape=(224, 224, 3))  # Ensure this matches your image size\n","\n","# Apply data augmentation (if needed)\n","x = data_augmentation(inputs)\n","\n","# Pass through base model in inference mode\n","x = base_model2(x, training=False)  # Make sure base_model2 is in inference mode\n","\n","# 🚀 Directly connect to Dense layer (REMOVE GlobalAveragePooling2D)\n","num_classes = len(train_data_all_10_percent.class_names)  # Ensure this variable is correct\n","# 🔥 Extract the correct tensor from the dictionary\n","x = x['dense_8']  # Replace 'dense_8' with the correct key if different\n","outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n","\n","# Define final model\n","model2 = tf.keras.Model(inputs, outputs)"],"metadata":{"id":"h9NHCDkwbDT9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Compile the model (Use categorical_crossentropy for one-hot encoded labels)\n","model2.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',  # Use categorical_crossentropy for one-hot encoded labels\n","    metrics=['accuracy']\n",")\n","\n","# Print model summary\n","model2.summary()\n"],"metadata":{"id":"P3ut7eiUXXU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["historyofimportedlibrary = model2.fit(train_data_all_10_percent,\n","                                     epochs =5,\n","                                     validation_data = test_data,\n","                                     validation_steps = int(0.15 * len(test_data))\n","                                     )\n","\n"],"metadata":{"id":"KAZUeURWeX1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_downloaded_model = model.evaluate(test_data)\n","results_downloaded_model"],"metadata":{"id":"YEggWRxoIZe8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds_probs = model2.predict(test_data,verbose =1 )"],"metadata":{"id":"y9gv8LeUIeD6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(preds_probs)"],"metadata":{"id":"N1V3V7rAIpx6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds_probs.shape"],"metadata":{"id":"pbD8Tw3HIxat"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#what does the first prediction probability array look like\n","preds_probs[0],len(preds_probs[0],sum(preds_probs[0]))"],"metadata":{"id":"GWvKK0qaI3kt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#finding the probability of the first image.\n","print(f\"The class with the highest probability is {preds_probs[0].argmax()} with a probability of {preds_probs[0].max()}\")"],"metadata":{"id":"d5A-N3gSJt6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#Get the pred classes of each label\n","pred_classes = preds_probs.argmax(axis=1)\n","\n","#How do the look?\n","pred_classes[:10]\n","\n","len(pred_classes)"],"metadata":{"id":"lJdBWV8JKTWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#To ge our test labels we need to unravel our test_data BatchDataset\n","\n","y_labels = []\n","for images, labels in test_data.unbatch():\n","  y_labels.append(labels.numpy().argmax())\n","y_labels[:10] #look at tge first 10\n"],"metadata":{"id":"6WlPbkgXhn3o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Evaluating our model's predictions\n","One way to check that our model's predictios array is in the same order as our test labels array is to find the accuracty score.\n"],"metadata":{"id":"lzmxVQi9iSxr"}},{"cell_type":"code","source":["results_downloaded_model"],"metadata":{"id":"wrW-Fkp-ihyp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","sklearn_accuracy = accuracy_score(y_true = y_labels,\n","                                  y_pred = pred_classes)\n","sklearn_accuracy"],"metadata":{"id":"M16jzaXeioEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","np.isclose(results_downloaded_model[1],sklearn_accuracy)"],"metadata":{"id":"ozk14BVQjVy6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Confusion matrix"],"metadata":{"id":"zld-3JamjkY8"}},{"cell_type":"code","source":["#get a list of classes names\n","class_names = test_data.class_names\n","class_names"],"metadata":{"id":"CADV3et2jt8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["make_confusion_matrix(y_true = y_labels,\n","                      y_pred = pred_classes,\n","                      classes = class_names,\n","                      figsize = (100,100),\n","                      text_size = 20,\n","                      savefig = True)"],"metadata":{"id":"KMQtUOGVkED_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Let's evaluate for classification report\n","from sklearn.metrics import classification_report\n","print(classification_report(y_true = y_labels,\n","                            y_pred = pred_classes))"],"metadata":{"id":"e_w30AgZkzks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Creating better visualization\n","classification_report_dict = classification_report(y_true = y_labels,\n","                                                    y_pred = pred_classes,\n","                                                    output_dict = True)\n","\n","classification_report_dict"],"metadata":{"id":"EVgCMkQ9lLeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names[98]"],"metadata":{"id":"YNROcVFllnI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classification_report_dict[\"99\"][\"f1-score\"]"],"metadata":{"id":"juuiU41_lpaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create empty dictionar\n","class_f1_scores = {}\n","# loop through classification report dictionary items\n","for k,v in classification_report_dict.items():\n","  if k == \"accuracy\":\n","    continue\n","  class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n","class_f1_scores"],"metadata":{"id":"Lx4B9575ltja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#trun f1-scores into dataframe for visualization\n","import pandas as pd\n","f1_scores_df = pd.DataFrame({\"class_names\":list(class_f1_scores.keys()),\n","                             \"f1-score\": list(class_f1_scores.values())}).sort_values(\"f1-score\",ascending = False)\n","f1_scores_df"],"metadata":{"id":"arTJAvhPmHec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fig, ax = plt.subplots(figsize = (12,25))\n","scores = ax.barh(range(len(f1_scores_df)),f1_scores_df[\"f1-score\"].values)\n","ax.set_yticks(range(len(f1_scores_df)))\n","ax.set_yticklabels(f1_scores_df[\"class_names\"])\n","ax.set_xlabel(\"f1-score\")\n","ax.set_title(\"f1-scores for 101 different food classes\")\n","ax.invert_yaxis(); #to reverse the order of plot"],"metadata":{"id":"wbXjP9q5m3jP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Visualizing predictions on custom images\n","\n","* Read in a targe image filepath using tf.io.read_file()\n","* Turn the image into a Tensor using tf.io.decode_image()\n","* Resize the image into a Tensor to be the same size as the images our model has trained on using tf.image.resize()\n","* Scale the image to get all of the pixel values between 0 & 1 (if necessary)\n"],"metadata":{"id":"tKjsz71nnsEZ"}},{"cell_type":"code","source":["# creat a function to load and prepare images\n","def load_and_prep_image(filename, img_shape = 224, scale = True):\n","  \"\"\"\n","  Reads in an image from filename, turns it into a tensor and reshapes into\n","  (224,224,3)\n","\n","  args:\n","   filename(str): Path to target image\n","   image_shape (int): height/width dimension of target imagesize\n","   scale (bool): whether to scale pixel values to range(0,1) or not by default set to true\n","\n","  Returns:\n","   Image tensor of image (image_shape, image_shape, 3)\n","  \"\"\"\n","  #read the file\n","  img = tf.io.read_file(filename)\n","  #Decode image into tensor\n","  img = tf.image.decode_image(img,channels=3)\n","  #resize the image\n","  img = tf.image.resize(img, size = [img_shape,img_shape])\n","\n","  #scale? yes or no\n","  if scale:\n","    #rescaling the image (if necessary)\n","    return img/255.\n","  else:\n","    return img# no need for efficient net models\n","\n"],"metadata":{"id":"jB4uY54HoBhQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Load a few random images from the test dataset\n","2. Make predictions on the loaded image\n","3. plot the original images along with the model's prediction"],"metadata":{"id":"Z5g8AsFspH_6"}},{"cell_type":"code","source":["#Make preds on a series of random images\n","import os\n","import random\n","plt.figure(figsize=(17,10))\n","for i in range(3):\n","  # choose a random image from a random class\n","  class_name = random.choice(class_names)\n","  filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n","  filepath = test_dir + \"/\" + class_name + \"/\" + filename\n","\n","  #load the image and make predictions\n","  img = load_and_prep_image(filepath, scale = False)\n","  pred = model.predict(tf.expand_dims(img,axis=0)) # the data need to be same as the expected.\n","  pred_class = class_names[pred.argmax()]\n","\n","  #plot the images\n","  plt.subplot(1,3,i+1)\n","  plt.imshow(img/255.)\n","  if class_name == pred_class:\n","    title_color = \"g\"\n","  else:\n","    title_color = \"red\"\n","  plt.title(f\"Actual: {class_name} , Pred: {pred_class}, prob : {preds_probs}\",color = title_color)\n","  plt.axis(False)"],"metadata":{"id":"7hWOnK5iqtaB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Finding the most wrong predictions\n","\n","view the wrong predictions with the highest prediction probability(or highest loss)\n","\n","this will give insights such as:\n","\n","* Data issues(wrong labels)\n","* Confusion classes"],"metadata":{"id":"KHMbD72xivun"}},{"cell_type":"markdown","source":["To find out where our model is most wrong we do the following:\n","1. Get all of the image file paths in the test dataset using list_files() method\n","2. Create a pandas Dataframe of the image filepaths, ground truth labels, predicted classes(from our model) , max prediction probabilities, prediction class names, ground truth class names.\n","3. use our DataFrame to find all the wrong predictions (where the ground truth label doen't match the prediction).\n","\n","4. Sort the DataFrame based on wrong predictions (have the highest prediction probability predictions at the top).\n","5. visualize the images with the highest prediction probabilities but have the wrong prediction."],"metadata":{"id":"JlUvpjVfkfjx"}},{"cell_type":"code","source":["# 1. Get all of the image file paths in the test dataset\n","filepaths = []\n","for filepath in test_data.list_files(\"/content/101_food_classes_10_percent/test/*/*.jpg\",shuffle=False): # first * means every directory in test and second * means every file.jpg in the selected directory before.\n","   filepaths.append(filepath.numpy())\n","filepaths[:10]"],"metadata":{"id":"oJYGvjyLlj8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2. Create a dataframe of different parameters for each of our test images\n","import pandas as pd\n","import pandas as pd\n","\n","pred_df = pd.DataFrame({\n","    \"img_path\": filepaths,\n","    \"y_true\": y_labels,\n","    \"y_pred\": pred_classes,\n","    \"pred_conf\": preds_probs.max(axis=1),\n","    \"y_true_classname\": [class_names[i] for i in y_labels],\n","    \"y_pred_classname\": [class_names[i] for i in pred_classes]\n","})\n","\n","# Display the first few rows\n","pred_df.head()\n",""],"metadata":{"id":"BSMRmFF8ovmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. find out our DataFrame which predictions are wrong\n","pred_df[\"pred_correct\"] = pred_df[\"y_true\"] == pred_df[\"y_pred\"]\n","pred_df.head()"],"metadata":{"id":"4HcaXq2gpNap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#4. sort our dataframe to have most wrong predictions at the top\n","top_100_wrong = pred_df[pred_df[\"pred_correct\"]==False].sort_values(\"pred_conf\",ascending = False)[:100]\n","top_100_wrong.head(20)#get the 20 samples of 100 dataframe"],"metadata":{"id":"S57q76Gnrbgu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. visualize the test data samples which have the wrong prediction but highest pred probability.\n","images_to_view = 9\n","start_index = 0\n","plt.figure(figsize = (10,10))\n","for i,row in enumerate(top_100_wrong[start_index:start_index + images_to_view].itertuples()):\n","  plt.subplot(3,3,i+1)\n","  img = load_and_prep_image(row[1],scale=False)\n","  _,_,_,_,pred_prob,y_true_classname,y_pred_classname, _  row # only access the required columns\n","  plt.imshow(img/255.)\n","  plt.title(f\"Actual: {y_true_classname}, Pred: {y_pred_classname},\\n Prob: {pred_prob}\")\n","  plt.axis(False)"],"metadata":{"id":"QdfRs9T8sLhR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Testing the model"],"metadata":{"id":"T03PY3ettS0k"}},{"cell_type":"code","source":["#get custom images\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/custom_food_images.zip"],"metadata":{"id":"2MN1RViWvBg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unzip_data(\"custom_food_images.zip\")"],"metadata":{"id":"swAg9kZfvjYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get the custom food images filepaths\n","custom_food_images = [\"custom_food_image/\"+img_path for img_path in os.listdir(\"custom_food_images\")]\n","custom_food_images"],"metadata":{"id":"tXA1JdCRvllt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#make predictions on and plot custom food images\n","for img in custom_food_images:\n","  img = load_and_prep_image(img,scale = False)# don't need to scale for our EfficientNetB0\n","  pred = model.predict(tf.expand_dims(img,axis=0))# make prediction on image with shape [1,224,224,3] same as the model trained on\n","  pred_class = class_names[pred.argmax()]#get the index with the hightes prediction probability\n","  plt.figure()\n","  plt.imshow(img/255.)\n","  plt.title(f\"pred: {pred_class}, prob: {pred.max(): .2f}\")\n","  plt.axis(False)"],"metadata":{"id":"VC2Zm1zqw4AW"},"execution_count":null,"outputs":[]}]}