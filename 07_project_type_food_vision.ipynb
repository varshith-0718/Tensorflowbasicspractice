{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOKoLbuW+D4N7L5vy2A8lII"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Food Vision\n"],"metadata":{"id":"InBpmjmYufrF"}},{"cell_type":"markdown","source":["## check GPU\n","\n","The GPUs in the colab can be not compatible with the mixed precision training.\n","\n","* K80 (not compatible)\n","* P100 (not compatible)\n","* Tesla T4 (compatible)\n","\n","Inorder to use mixed precision training we need access to a Tesla T4 GPU.\n","or if using own GPU it needs a score of 7.0+\n","\n","https://developer.nvidia.com/cuda-gpus"],"metadata":{"id":"FLSHXB-9u4DF"}},{"cell_type":"code","source":["!nvidia-smi -L"],"metadata":{"id":"x1W2idAfyW2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","# Connect to TPU\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","    print(\"✅ TPU detected and initialized\")\n","except:\n","    strategy = tf.distribute.get_strategy()  # Use default strategy if no TPU\n","    print(\"⚠️ TPU not found, using default strategy\")\n"],"metadata":{"id":"md3UczODr3zG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Getting helper functions"],"metadata":{"id":"2LECdS5Qy7zr"}},{"cell_type":"code","source":["#using the helper funtions\n","!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"],"metadata":{"id":"U66NDr3OyaKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import helper functions that can be used\n","from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"],"metadata":{"id":"IJTFHp0zzOyt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#using tensorflow datasets to download data\n","\n","https://www.tensorflow.org/datasets/overview"],"metadata":{"id":"TEByJYbhzhYt"}},{"cell_type":"code","source":["# Get Tensorflow Datasets\n","import tensorflow_datasets as tfds"],"metadata":{"id":"KPOpWg_21c1I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#List all available datasets\n","datasets_list = tfds.list_builders() #get all available datasets in TFDS\n","print(\"food101\" in datasets_list) #is our target dataset in the list of TFDS dataset?\n"],"metadata":{"id":"cem7jYTbfwl0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","(train_data, test_data), ds_info = tfds.load(name = \"food101\",\n","                                             split = [\"train\", \"validation\"],\n","                                             shuffle_files = True,\n","                                             as_supervised = True, #data gets returned in tuple format(data,label)\n","                                             with_info = True)"],"metadata":{"id":"ZkwEUwF7gEre"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Exploring the FOOD101 data from Tensorflow Datasets\n","\n","we want to find:\n","* class names\n","* The shape of our inputs data (image tensor)\n","* The datatype of our input data\n","* Waht the labels look like(e.g are they one-hot encoded or are they label encoded)\n","* do the labels match up with the class names?"],"metadata":{"id":"FDXcDSws_dZq"}},{"cell_type":"code","source":["# Feature of Food101 TFDS\n","ds_info.features"],"metadata":{"id":"k1hHL6Ni_FH3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get the class names\n","class_names = ds_info.features[\"label\"].names\n","class_names[:10]"],"metadata":{"id":"XtbxCIfW_PLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Take one sample of the train data\n","train_one_sample = train_data.take(1) #samples are in format(image_tensor, label)\n","train_one_sample\n"],"metadata":{"id":"Bfpc0VycAKaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#output info about the training sample\n","for image, label in train_one_sample:\n","  print(f\"\"\"\n","  image shape: {image.shape}\n","  image datatype: {image.dtype}\n","  target class from Food101 (tensor form): {label}\n","  target class from label (integer): {label.numpy()}\n","  Class name (str form): {class_names[label.numpy()]}\n","  \"\"\")"],"metadata":{"id":"CIs-GX3vAbw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#what does the image tensor from the TFDS's FOOD101 look like\n","image"],"metadata":{"id":"HmyH6nGuBhs0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What are the min and max values of our image\n","import tensorflow as tf\n","tf.reduce_min(image), tf.reduce_max(image)"],"metadata":{"id":"BSZ6TSCVBo1s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Plot an image from the tensorflow datasets\n"],"metadata":{"id":"22YD32OvB4GQ"}},{"cell_type":"code","source":["#Plot an image tensor\n","import matplotlib.pyplot as plt\n","plt.imshow(image)"],"metadata":{"id":"auWfLPIXB8Gy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title(class_names[label.numpy()]) #Add title to the image to verify the label is assosciateed with the right image\n","plt.axis(False)"],"metadata":{"id":"WbqRaJp8FGSH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create preprocessing functions for our data\n","(Neural Network works best when data is in certain way (e.g. batched, normalized, etc).\n","\n","not all data comes like this.\n","\n","inorder to get it ready for a neural network, you'll often have to write preprocessing functions and map it to your data.\n","\n","what we know about our data:\n","* In 'unit8' datatype\n","* Comprised of all different size tensors( different sized images)\n","* Not scaled (the pixel values are between 0 & 255)\n","\n","what we know models like:\n","* Data in 'float32' dtype (or for mixed precision 'float16' and 'float32')\n","* For batches, TensorFlow likes all of the tensors within a batch to be of the same size\n","* Scaled (values between 0 & 1 ) also called normalized tensors generally perform better\n","\n","we use EfficientNetBX pretrained model from tf.keras.applicatinos we don't need to architectures have rescaling built-in).\n","\n","This means our funtions needs to:\n","1. Reshape our images to all the same size\n","2. Convert the dtype of our image tensors from uint8 to float32"],"metadata":{"id":"QPa53152FlaO"}},{"cell_type":"code","source":["#(image,label)"],"metadata":{"id":"sw2yIZuqFqpN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make a function for preprocessing images\n","def preprocess_img(image, label ,img_shape = 224):\n","  \"\"\"\n","  Converts image datatype from 'uint8' -> 'float32'\n","  Reshapes the image to [img_shape, img_shape, color_channels]\n","  \"\"\"\n","  image = tf.image.resize(image, [img_shape, img_shape])# reshape target image\n","  image = image / 255.\n","  return tf.cast(image, tf.float32), label # return (float_image, label) tuple"],"metadata":{"id":"aJdkUlh0Uv9b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess a single sample image and check the outputs\n","preprocessed_img = preprocess_img(image, label)[0]\n","\n","print(f\"Image before preprocessing:\\n {image[:2]}...\\n Shape: {image.shape},\\nDatatype: {image.dtype}\\n\")\n","print(f\"Image after preprocessing:\\n {preprocessed_img[:2]}...,\\n Shape: {preprocess_img.shape},\\n Datatype :{preprocess_img.dtype}\")\n"],"metadata":{"id":"1J8KkXEvVDxf"},"execution_count":null,"outputs":[]}]}